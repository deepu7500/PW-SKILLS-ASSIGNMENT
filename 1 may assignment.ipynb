{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ee29118",
   "metadata": {},
   "source": [
    "# ans 1-\n",
    "A contingency matrix, also known as a confusion matrix or an error matrix, is a table used to evaluate the performance of a classification model. It provides a detailed breakdown of the predicted class labels versus the actual class labels for a set of data points. It's particularly useful for assessing the accuracy of a classification model and understanding the types of errors it makes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9156eb19",
   "metadata": {},
   "source": [
    "# ans 2-\n",
    "\n",
    "A pair confusion matrix is a specialized type of confusion matrix that is used in situations involving pairwise classification or binary classification of pairs of samples.\n",
    "In a pair confusion matrix, you're dealing with pairs of samples and their pairwise relationships. \n",
    "\n",
    "In a regular confusion matrix, you have four categories: true positive, false positive, true negative, and false negative, which are based on the actual and predicted class labels of individual instances.  A regular confusion matrix is typically used in standard binary or multi-class classification scenarios.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0b7693",
   "metadata": {},
   "source": [
    "# ans 3-\n",
    "In natural language processing (NLP), extrinsic measures refer to evaluation metrics that assess the performance of a language model or other NLP system within the context of a specific downstream task. These tasks are usually higher-level applications that involve using the language model's outputs as input to perform a certain task, such as text classification, machine translation, question answering, sentiment analysis, named entity recognition, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435f9836",
   "metadata": {},
   "source": [
    "# ans 4-\n",
    "Intrinsic measures, also known as standalone measures, are evaluation metrics that directly assess the performance of a model on a specific subtask or property, without considering its application to a broader task.\n",
    "Example - NLP\n",
    "\n",
    "intrinsic measures focus on evaluating specific model properties or subtasks, while extrinsic measures assess a model's performance within the context of a broader application. Both types of measures provide complementary insights into a model's strengths and weaknesses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ae35d6",
   "metadata": {},
   "source": [
    "# ans 5-\n",
    "A confusion matrix represents the prediction summary in matrix form. It shows how many prediction are correct and incorrect per class. It helps in understanding the classes that are being confused by model as other class.\n",
    "\n",
    "the confusion matrix can be used to identify strengths and weaknesses of a model:\n",
    "\n",
    "True Positives (TP)- These are instances that were correctly predicted as positive. High TP counts indicate that the model is correctly identifying positive instances.\n",
    "\n",
    "False Positives (FP)- These are instances that were incorrectly predicted as positive when they are actually negative. High FP counts indicate that the model is making false positive errors.\n",
    "\n",
    "False Negatives (FN)- These are instances that were incorrectly predicted as negative when they are actually positive. High FN counts indicate that the model is making false negative errors.\n",
    "\n",
    "True Negatives (TN)- These are instances that were correctly predicted as negative. High TN counts indicate that the model is correctly identifying negative instances.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7983c12",
   "metadata": {},
   "source": [
    "# ans 6-\n",
    "Unsupervised learning algorithms are used to find patterns, structures, or relationships in data without the use of labeled outcomes. unsupervised learning algorithms can be more challenging due to the absence of ground truth labels. \n",
    "\n",
    "there are several intrinsic measures that can provide insights into the quality of the learned clusters or representations like-\n",
    "* silhouette score\n",
    "* davies bouldin index\n",
    "* homogeneity,completeness and V-measure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90998be3",
   "metadata": {},
   "source": [
    "# ans 7-\n",
    "limitations of using accuracy and how they can be addressed-\n",
    "* Accuracy treats all types of errors equally like false positives and false negatives. However, in some applications, certain types of errors might be more critical than others.\n",
    "\n",
    "Use evaluation metrics that reflect the costs associated with different types of errors, like using a cost-sensitive approach or defining a custom loss function.\n",
    "\n",
    "* Accuracy might not be suitable for ordered or multiclass problems where predicting the exact class label matters less than the overall ranking or grouping of classes.\n",
    "\n",
    " so we use alternatives for ordinal problems use metrics like Mean Absolute Error or Cumulative Accuracy Profile. and for multiclass problems, use metrics like precision, recall, F1-score, or macro/micro-average.\n",
    "\n",
    "* In cases where one class is rare, the model might appear highly accurate due to the high proportion of the dominant class, even if it performs poorly on the minority class.\n",
    "\n",
    " this can address by focus on metrics that provide insights into the performance of both classes, such as precision and recall.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aa8c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
