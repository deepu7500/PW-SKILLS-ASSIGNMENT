{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a24461f6",
   "metadata": {},
   "source": [
    "# ans 1-\n",
    "In the context of dimensionality reduction and Principal Component Analysis, a projection refers to the process of transforming high-dimensional data onto a lower-dimensional subspace.\n",
    "\n",
    "The projection step in PCA is the process of mapping the original data points onto the lower-dimensional subspace spanned by the principal components. This transformation is achieved by taking the dot product of the data points with the principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c49d8d4",
   "metadata": {},
   "source": [
    "# ans 2-\n",
    "PCA  involves an optimization problem that aims to find the directions (principal components) in which the data has the maximum spread (variance). The optimization problem is essentially about identifying the linear transformations that best represent the data in a lower-dimensional space while retaining as much of the original variability as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52184df0",
   "metadata": {},
   "source": [
    "# ans 3-\n",
    "The covariance matrix plays a crucial role in PCA. In the PCA process, the covariance matrix of the standardized data is calculated, and its eigenvectors are found. These eigenvectors represent the principal components of the data. The eigenvectors with the largest eigenvalues capture the directions of maximum variance in the data, and these directions correspond to the principal components.\n",
    "\n",
    "Mathematically, the covariance between two variables X and Y can be defined as-\n",
    "cov(X, Y) = E[(X - E[X]) * (Y - E[Y])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f9e863",
   "metadata": {},
   "source": [
    "# ans 4-\n",
    "The number of principal components determines how much variance in the data is retained and how well the reduced-dimensional data represents the original dataset.\n",
    "\n",
    "The choice of the number of principal components in PCA is a trade-off between retaining enough variance for meaningful representation and reducing the dimensionality of the data while avoiding information loss and overfitting.\n",
    "\n",
    " Selecting an appropriate number of components requires careful consideration of the specific application and the characteristics of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2116c8",
   "metadata": {},
   "source": [
    "# ans 5-\n",
    "PCA (Principal Component Analysis) can be used for feature selection as a means to reduce the dimensionality of a dataset while retaining as much relevant information as possible.\n",
    "benefits of using pca fo r feature selectio are-\n",
    "\n",
    "1.One of the primary benefits of PCA-based feature selection is that it reduces the number of features in the dataset.\n",
    "\n",
    "2.PCA can help in reducing this multicollinearity. Collinearity can lead to instability and high variances in model estimates.\n",
    "\n",
    "3.PCA can serve as a preprocessing step to reduce feature dimensionality before training models. \n",
    "\n",
    "4. Reduced-dimensional data is easier to visualize\n",
    "\n",
    "5.PCA tends to prioritize capturing the most significant variance in the data, which can lead to the removal of noise and irrelevant information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3356cc",
   "metadata": {},
   "source": [
    "# ans 6-\n",
    "PCA has a wide range of applications in data science and machine learning.\n",
    "* feature engineering\n",
    "* dimensionality reduction\n",
    "* noise reduction\n",
    "* collinearity management\n",
    "* preprocessing for machine learning\n",
    "* image and video compression\n",
    "* financial modelling\n",
    "* speech and audio processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efea10e2",
   "metadata": {},
   "source": [
    "# ans 7-\n",
    "Spread typically refers to how data points are dispersed or distributed in a particular dimension or direction.\n",
    "Variance is a statistical measure that quantifies the degree of dispersion of a set of data points around their mean.\n",
    "\n",
    "The relationship between spread and variance in PCA is that variance can be thought of as a measure of spread, specifically the spread of data points along a principal component axis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2dc6bd",
   "metadata": {},
   "source": [
    "# ans 8-\n",
    "PCA uses the spread and variance of the data to identify principal components by seeking directions in the data space along which the spread  of the data points is maximized.\n",
    "\n",
    "The goal of PCA is to find a set of orthogonal axes (principal components) in the original feature space such that when the data is projected onto these axes, the spread of the projected data is maximized along the first axis  then the second most spread along the second axis, and so on. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ad96d8",
   "metadata": {},
   "source": [
    "# ans 9-\n",
    "PCA  handles data with varying levels of variance in different dimensions by identifying the directions of maximum variance  in the data space. This means that dimensions with high variance will contribute more to the principal components, while dimensions with low variance will have relatively less influence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d181a3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
