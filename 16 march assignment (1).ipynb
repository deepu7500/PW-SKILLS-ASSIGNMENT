{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e43d99b",
   "metadata": {},
   "source": [
    "ans 1-> \n",
    "         overfiting- it means that your model makes not accurate predictions.\n",
    "        in this case,model perfroms very well for training data but has \n",
    "       poor performance with test data.\n",
    "        underfiting- it means that your model make accurate predection,but intially incorrect prediction.\n",
    "        in this cae,model does not perform well on training data and is unable to generalize well on \n",
    "        the new data.\n",
    "        \n",
    "        consequens are-\n",
    "        an underfit model rsult in high prediction error for both training and test data.\n",
    "        an overfit model gives a very low prediction error on training data,but a very high prediction error on test data.\n",
    "         \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995a68d0",
   "metadata": {},
   "source": [
    "ans 2-> \n",
    "    overfiting occur when model performs well on training data but generalize poorely to new data.it is very\n",
    "     common problem in machine learning.\n",
    "    some steps used to reduce the overfiting are-\n",
    "    (1) simplifing the model\n",
    "    the first step is to decrease the complexity by reduce the number o neurons to make network smaller.\n",
    "    \n",
    "    (2) early stopping\n",
    "    this rule provide guidance as to how many oterations can be run before model begins to overfit.\n",
    "    \n",
    "    (3)use data augmentation\n",
    "    it means increasing the size of the data that is increasing the number of images present in dataset.some\n",
    "    of popular image augmentation techniques are flipping,translation, rotation,acaling,changing,brightness.\n",
    "    \n",
    "    (4)use regularization\n",
    "    it used to reduce the complexity of the model.it does so by sdding a penalty termt o loss function.\n",
    "    the mos commom are L1 and L2. L1 aim to minimize the absolute value of weights and L2 aims to\n",
    "    minimize the squared magnitude of weights.\n",
    "    \n",
    "    (5) use dropouts\n",
    "    it randomly drops neurons from the neural network during training in each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d37838",
   "metadata": {},
   "source": [
    "ans 3->\n",
    "A statistical model or a machine learning algorithm is said to have underfitting when it \n",
    "cannot capture the underlying trend of the data, i.e., it only performs well on training\n",
    "data but performs poorly on testing data.  Underfitting destroys the accuracy of our machine learning model. \n",
    "\n",
    "(1)Its occurrence simply means that our model or the algorithm does not fit the data well enough. \n",
    "(2)It usually happens when we have fewer data to build an accurate model and also when we try to build a linear model\n",
    "with fewer non-linear data. In such cases, the rules of the machine learning model are too easy and flexible \n",
    "to be applied to such minimal data and therefore the model will probably make a lot of wrong predictions. \n",
    "Underfitting can be avoided by using more data and also reducing the features by feature selection. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f63052",
   "metadata": {},
   "source": [
    "ans 4-> \n",
    "    Bias: Assumptions made by a model to make a function easier to learn. \n",
    "    It is actually the error rate of the training data. When the error rate has a high value, \n",
    "    we call it High Bias and when the error rate has a low value, we call it low Bias.\n",
    "\n",
    "Variance:  The difference between the error rate of training data and testing data is called variance.\n",
    "    If the difference is high then it’s called high variance and when the difference of errors is low then \n",
    "    it’s called low variance. Usually, we want to make a low variance for generalized our model.\n",
    "    \n",
    "    A model that exhibits small variance and high bias will underfit the target, while a model with high variance \n",
    "    and little bias will overfit the target.A model with high variance may represent the data set accurately but \n",
    "    could lead to overfitting to noisy or otherwise unrepresentative training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a5b3c",
   "metadata": {},
   "source": [
    "ans 5->\n",
    "If a model is showing high accuracy during the training phase but fails to show similar\n",
    "accuracy during the testing phase it indicates overfitting.\n",
    "If a model fails to show satisfactory accuracy during the training phase itself it means the model is underfitting.\n",
    "\n",
    "You can determine the difference between an underfitting and overfitting experimentally by comparing fitted\n",
    "models to training-data and test-data. These plots will show you the accuracy of the model, \n",
    "as function of some parameter (e.g. 'complexity'), for both the One normally chooses the model that\n",
    "does the best on the test-data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31a48a9",
   "metadata": {},
   "source": [
    "ans 6->\n",
    "Bias is a phenomenon that occurs in the machine learning model wherein an algorithm is \n",
    "used and it does not fit properly. Variance specifies the amount of variation that the estimate of \n",
    "the target function will change if different training data was used. Bias refers to the difference between \n",
    "predicted values and actual values.\n",
    "\n",
    "In machine learning terminology, underfitting means that a model is too general, leading to high bias, \n",
    "while overfitting means that a model is too specific, leading to high variance. When training a model, \n",
    "it is important to balance these two.Since you can’t realistically avoid bias and variance altogether,\n",
    "this is called the bias-variance tradeoff.\n",
    "\n",
    "Examples of high-bias machine learning algorithms include:\n",
    "    Linear Regression, Linear Discriminant Analysis and Logistic Regression.\n",
    "    \n",
    "example of high-variance machine learning alogrithms include:\n",
    "   k-Nearest Neighbors (k=1), Decision Trees and Support Vector Machines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28767cb6",
   "metadata": {},
   "source": [
    "ans 7->\n",
    "Regularization means restricting a model to avoid overfitting by shrinking \n",
    "the coefficient estimates to zero. When a model suffers from overfitting,\n",
    "we should control the model's complexity. Technically, regularization avoids overfitting by \n",
    "adding a penalty to the model's loss function.\n",
    "There are three commonly used regularization techniques\n",
    "(1) L2 regularization\n",
    "(2) L1 regularization\n",
    "(3) Elastic Net\n",
    "\n",
    "how regularization techniques work\n",
    "\n",
    "(1)LASSO (Least Absolute Shrinkage and Selection Operator) is also called L1.LASSO’s penalty term is the penalty parameter \n",
    "lambda multiplied by the sum of the absolute value of the coefficients. Because LASSO’s coefficients may shrink to zeros,\n",
    "it can be used for automatic feature selection.\n",
    "\n",
    "(2)Ridge is also called L2 regularization.Ridge shrinks the model coefficients based on the sum of the squared coefficients. \n",
    "Ridge does not shrink the model coefficients to zero.\n",
    "\n",
    "(3)Elastic net’s penalty term is a combination of LASSO and Ridge regression’s penalty term. \n",
    "It sets some coefficients to zeros, but the number is smaller than LASSO.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
